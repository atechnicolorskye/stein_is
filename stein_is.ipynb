{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median(x):\n",
    "    x = tf.reshape(x, [-1])\n",
    "    med = tf.floordiv(tf.shape(x)[0], 2)\n",
    "    check_parity = tf.equal(tf.to_float(med), tf.divide(tf.to_float(tf.shape(x)[0]), 2.))\n",
    "    def is_true():\n",
    "        return 0.5 * tf.reduce_sum(tf.nn.top_k(x, med+1).values[-2:]) \n",
    "    def is_false():\n",
    "        return tf.nn.top_k(x, med+1).values[-1]\n",
    "    return tf.cond(check_parity, is_true, is_false) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GMM(object):\n",
    "    def __init__(self, mu, sigma, weights, dim):\n",
    "        # Required parameters \n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.weights = weights\n",
    "        self.dim = dim\n",
    "        \n",
    "    def log_px(self, x):\n",
    "        # log_px = log(sum(exp(log(w_i) + log(p_i(x)))))\n",
    "        log_px = []\n",
    "        for i in range(weights.shape[0]):\n",
    "            mu_, sigma_ = self.mu[i] * tf.ones(dim), self.sigma[i] * tf.ones(dim)\n",
    "            mvn = ds.MultivariateNormalDiag(loc=mu_, scale_diag=sigma_)\n",
    "            # Calculate log_px for each component\n",
    "            log_px_i = tf.reduce_logsumexp(mvn.log_prob(x)) + tf.log(tf.to_float(weights[i]))\n",
    "            log_px.append(log_px_i)\n",
    "        return tf.reduce_logsumexp(log_px)\n",
    "    \n",
    "    def d_log_px(self, x):\n",
    "        # d_log_px = 1 / exp(log(sum(exp(log(w_i) + log(p_i(x)))))) \n",
    "        #            * sum(exp(log(w_i) + log(p_i(x)) + log(-(x - mu)/sigma^2)))\n",
    "        # Use symbolic differentiation instead\n",
    "        log_px = self.log_px(x)\n",
    "        return tf.gradients(log_px, [x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mu = np.array([1., -1.]); sigma = np.sqrt(np.array([0.1, 0.05])); weights = np.array([1./3, 2./3]); dim=6\n",
    "mu = np.array([[-.5], [.5], [-1.], [1.0], [-1.5], [1.5], [-2.0], [2.0], [-2.5], [2.5]]).astype(np.float32)\n",
    "sigma = 2 * np.ones(10).astype(np.float32)\n",
    "weights = (1/10.0 * np.ones(10)).astype(np.float32)\n",
    "dim = 2\n",
    "gmm = GMM(mu, sigma, weights, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SteinIS(object):\n",
    "    def __init__(self, gmm_model, mu, sigma, dim, n_leaders, n_followers, step_size_master=1., step_size_beta=0.35): # n_trials, step_size=0.01):\n",
    "        # Required parameters\n",
    "        self.gmm_model = gmm_model\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dim = dim\n",
    "        # Check if it works \n",
    "        self.n_leaders = n_leaders\n",
    "        self.n_followers = n_followers\n",
    "        # self.n_trials = n_trials\n",
    "        self.step_size = 1\n",
    "        self.step_size_master = step_size_master\n",
    "        self.step_size_beta = step_size_beta\n",
    "        self.eps = 1e-10\n",
    "        \n",
    "        # Set seed\n",
    "        seed = 30\n",
    "        \n",
    "        # Intialisation\n",
    "        self.B, self.B_density, self.A = self.initialise_variables()\n",
    "        self.pB = self.gmm_model.log_px(self.B)\n",
    "        \n",
    "        # Register functions for debugging\n",
    "        self.k_A_A, self.sum_grad_A_k_A_A, self.A_Squared, self.h = self.construct_map()\n",
    "        self.k_A_B, self.sum_grad_A_k_A_B = self.apply_map()        \n",
    "        # self.A, self.B, self.grad_B_k_A_B, self.grad_B_sum_grad_A_k_A_B, self.grad_B_phi_B_ = self.svgd_update()\n",
    "        # self.q_density = self.density_update()\n",
    "        \n",
    "        \n",
    "    def initialise_variables(self):\n",
    "        init_distribution = tf.contrib.distributions.MultivariateNormalDiag(self.mu * tf.ones(dim), self.sigma * tf.ones(dim))\n",
    "        \n",
    "        # followers = tf.reshape(init_distribution.sample(self.n_trials * self.n_followers, seed=123), [self.n_trials, self.n_followers, self.h_dim] \n",
    "        # leaders = tf.reshape(init_distribution.sample(self.n_trials * self.n_leaders, seed=123), [self.n_trials, self.n_leaders, self.h_dim] \n",
    "        \n",
    "        followers = tf.reshape(init_distribution.sample(self.n_followers, seed=123), [self.n_followers, self.dim]) \n",
    "        q_density = init_distribution.log_prob(followers)\n",
    "        leaders = tf.reshape(init_distribution.sample(self.n_leaders, seed=123), [self.n_leaders, self.dim])                   \n",
    "        return followers, q_density, leaders\n",
    "                             \n",
    "    def construct_map(self):\n",
    "        # Calculate ||leader - leader'||^2/h_0, refer to leader as A as in SteinIS\n",
    "        x2_A_A_T = 2. * tf.matmul(self.A, tf.transpose(self.A)) # 100 x 100\n",
    "        A_Squared = tf.reduce_sum(tf.square(self.A), keep_dims=True, axis=1) # 100 x 1\n",
    "        A_A_Distance_Squared = A_Squared - x2_A_A_T + tf.transpose(A_Squared) # 100 x 100\n",
    "        h_num = tf.square(median(tf.sqrt(A_A_Distance_Squared)))\n",
    "        h_dem = 2. * tf.log(tf.to_float(self.n_leaders) + 1.)\n",
    "        h = tf.stop_gradient(h_num / h_dem)\n",
    "        k_A_A = tf.exp(-A_A_Distance_Squared / h)\n",
    "        # Can't use vanilla tf.gradients as it sums dy/dx wrt to dx, want sum dy/dx wrt to dy, tf.map_fn is not available\n",
    "        sum_grad_A_k_A_A = tf.stack([tf.reduce_sum(tf.gradients(k_A_A[i, :], self.A)[0], axis=0) for i in range(self.n_leaders)])\n",
    "        return k_A_A, sum_grad_A_k_A_A, A_Squared, h\n",
    "        \n",
    "    def apply_map(self):\n",
    "        # Calculate ||leader - follower||^2/h_0, refer to follower as B as in SteinIS\n",
    "        x2_A_B_T = 2. * tf.matmul(self.A, tf.transpose(self.B))\n",
    "        B_Squared = tf.reduce_sum(tf.square(self.B), keep_dims=True, axis=1)\n",
    "        A_B_Distance_Squared = self.A_Squared - x2_A_B_T + tf.transpose(B_Squared)\n",
    "        k_A_B = tf.exp(-A_B_Distance_Squared / self.h)\n",
    "        sum_grad_A_k_A_B = tf.stack([tf.reduce_sum(tf.gradients(k_A_B[i, :], self.A)[0], axis=0) for i in range(self.n_leaders)])\n",
    "        return k_A_B, sum_grad_A_k_A_B\n",
    "                    \n",
    "    def svgd_update(self):\n",
    "        self.k_A_A, self.sum_grad_A_k_A_A, self.A_Squared, self.h = self.construct_map()\n",
    "        self.k_A_B, self.sum_grad_A_k_A_B = self.apply_map()\n",
    "        self.d_log_pA = self.gmm_model.d_log_px(self.A)\n",
    "        sum_d_log_pA_T_k_A_A = tf.matmul(self.k_A_A, self.d_log_pA)\n",
    "        phi_A = (sum_d_log_pA_T_k_A_A + self.sum_grad_A_k_A_A) / self.n_leaders\n",
    "        A = self.A + self.step_size * phi_A  \n",
    "        sum_d_log_pA_T_k_A_B = tf.matmul(self.k_A_B, self.d_log_pA)\n",
    "        phi_B = (sum_d_log_pA_T_k_A_B + self.sum_grad_A_k_A_B) / self.n_leaders\n",
    "        B = self.B + self.step_size * phi_B \n",
    "        # Probably have to fix this too\n",
    "        # grad_B_phi_B = [tf.gradients(phi_B[i, :], self.B)[0] for i in range(self.n_followers)]\n",
    "        # grad_B_phi_B = tf.convert_to_tensor(grad_B_phi_B)\n",
    "        grad_B_k_A_B = [tf.gradients(self.k_A_B[:, i], self.B)[0] for i in range(self.n_followers)]\n",
    "        grad_B_sum_grad_A_k_A_B = [tf.gradients(self.sum_grad_A_k_A_B[0], self.B)[0] for i in range(self.n_followers)]\n",
    "        grad_B_phi_B_ = tf.gradients(phi_B, self.B)\n",
    "        return A, B, grad_B_k_A_B, grad_B_sum_grad_A_k_A_B, grad_B_phi_B_\n",
    "    \n",
    "    def density_update(self):\n",
    "        I = tf.eye(self.dim)\n",
    "        inv_abs_det_I_grad_B_phi = tf.map_fn(lambda x: 1./tf.abs(tf.matrix_determinant(I + self.step_size * x)), self.grad_B_phi_B)\n",
    "        return tf.multiply(self.B_density, inv_abs_det_I_grad_B_phi) \n",
    "\n",
    "    def main(self, iteration):\n",
    "        for i in range(1, iteration+1):\n",
    "            self.step_size = self.step_size_master * (1. + i) ** (-self.step_size_beta)\n",
    "            self.A, self.B, self.phi_B, self.grad_B_phi_B = self.svgd_update()\n",
    "            self.q_density = self.density_update()\n",
    "            if i % 10 == 0:\n",
    "                self.pB = self.gmm_model.log_px(self.B)\n",
    "                self.importance_weights = self.pB / self.q_density\n",
    "                self.normalisation_constant = tf.reduce_sum(self.importance_weights) / self.n_followers\n",
    "                print 'Iteration ', str(i), ' done'\n",
    "        self.final_B = self.B\n",
    "        return self.normalisation_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mu = 0.; sigma = 3.; dim = 6; n_leaders = 100; n_followers = 100;\n",
    "initial_mu = np.float32(0.)\n",
    "initial_sigma = np.float32(1.)\n",
    "n_leaders = 100\n",
    "n_followers = 100\n",
    "model = SteinIS(gmm, initial_mu, initial_sigma, dim, n_leaders, n_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w] = sess.run([tf.gradients(model.sum_grad_A_k_A_B, model.B)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w.shape, x[0].shape, y.shape, z[0].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Look into using einsum https://www.tensorflow.org/api_docs/python/tf/einsum\n",
    "for i in range(n_followers):\n",
    "    if i == 0:\n",
    "        grad_B_phi_B = np.dot(w.T, x[i]).reshape((1, 2, 2))\n",
    "    else:\n",
    "        grad_B_phi_B = np.concatenate((grad_B_phi_B, np.dot(w.T, x[i]).reshape((1, 2, 2))), 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grad_B_phi_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.79536295e+00,   5.79536295e+00],\n",
       "        [ -2.18037513e-07,   1.39349154e-07],\n",
       "        [  6.27294412e-07,  -8.71084410e-07],\n",
       "        [ -1.64126527e+00,   3.58454108e-01],\n",
       "        [ -1.90087390e-04,  -2.88216688e-05],\n",
       "        [ -2.72020634e-16,  -5.82042131e-17],\n",
       "        [ -6.11541218e-09,  -1.37098888e-09],\n",
       "        [  2.87248719e-12,  -1.03976142e-11],\n",
       "        [  1.45082653e-01,  -8.06589946e-02],\n",
       "        [ -3.71138594e-06,   2.95813470e-06],\n",
       "        [  1.03637021e-12,  -1.59385818e-12],\n",
       "        [ -6.43289013e-07,   3.13343179e-07],\n",
       "        [  2.35033895e-07,  -4.94986921e-07],\n",
       "        [ -2.46110857e-11,   1.61467974e-11],\n",
       "        [ -1.43497506e-24,   4.98765048e-25],\n",
       "        [  5.93418710e-18,  -1.07137235e-17],\n",
       "        [ -1.49860404e-16,   1.03180392e-16],\n",
       "        [ -8.53421153e-12,   4.90776690e-12],\n",
       "        [  1.51301744e-08,  -1.40629766e-08],\n",
       "        [ -2.03798801e-16,   1.40174821e-16],\n",
       "        [  0.00000000e+00,   0.00000000e+00],\n",
       "        [  3.21912169e-02,   2.15754565e-02],\n",
       "        [ -1.83964753e+00,  -3.78275871e-01],\n",
       "        [ -6.89038604e-24,   2.53966471e-24],\n",
       "        [ -3.55463228e-12,   5.05659924e-12],\n",
       "        [  8.92602259e-07,  -1.52621999e-06],\n",
       "        [ -1.14071426e-11,   5.72282196e-12],\n",
       "        [ -3.00550834e-10,   9.67958075e-11],\n",
       "        [ -2.74970887e-07,   4.38495746e-08],\n",
       "        [ -6.84131082e-05,   4.33027089e-05],\n",
       "        [  4.12523270e-01,   3.45352554e+00],\n",
       "        [ -1.66515831e-03,   3.38234310e-03],\n",
       "        [  1.83103512e-05,  -3.55634838e-05],\n",
       "        [ -5.60060202e-04,   1.41640718e-04],\n",
       "        [ -3.05940875e-06,   1.07841288e-06],\n",
       "        [  3.09283332e-09,   1.74019310e-09],\n",
       "        [ -1.75073114e-03,  -3.20483581e-04],\n",
       "        [ -3.32070658e-06,   2.49508230e-06],\n",
       "        [ -1.42257102e-02,  -1.38377864e-03],\n",
       "        [ -2.77402047e-02,   5.90174720e-02],\n",
       "        [ -2.17048089e-20,   1.24842694e-20],\n",
       "        [ -2.27886510e-08,   7.37423456e-10],\n",
       "        [ -4.07824554e-02,   7.37409852e-03],\n",
       "        [ -2.86950637e-03,   8.87913280e-04],\n",
       "        [  2.09296053e-10,  -1.43014905e-10],\n",
       "        [ -1.85818815e+00,   1.41925216e+00],\n",
       "        [ -5.15444243e-10,   1.25356669e-11],\n",
       "        [ -2.71585394e-14,  -2.94226212e-16],\n",
       "        [ -1.20050588e-16,   8.92066777e-17],\n",
       "        [ -2.40350533e+00,   9.72441912e-01],\n",
       "        [ -4.57837521e-18,   2.40222473e-18],\n",
       "        [ -1.77390604e-07,   2.80942459e-07],\n",
       "        [  9.50920060e-02,  -5.18771447e-03],\n",
       "        [ -8.28533173e-02,   3.07583237e+00],\n",
       "        [ -3.07221003e-02,  -2.53289882e-02],\n",
       "        [ -9.90871621e-12,   2.37983765e-12],\n",
       "        [ -8.30996711e-08,   1.78533767e-07],\n",
       "        [ -2.02788920e-15,   4.82662243e-16],\n",
       "        [  3.28151726e-19,  -1.47077345e-18],\n",
       "        [  7.43252437e-09,  -3.07786285e-09],\n",
       "        [ -6.39299884e-08,   9.81186616e-08],\n",
       "        [ -4.03977090e-13,   3.17268320e-14],\n",
       "        [ -9.33942160e-13,   5.80036724e-13],\n",
       "        [ -7.55831649e-13,  -1.52741684e-13],\n",
       "        [ -1.35686823e-10,   5.86286852e-11],\n",
       "        [ -4.41794796e-08,   9.36354017e-09],\n",
       "        [  3.19687475e-04,  -3.92193469e-04],\n",
       "        [ -1.30877384e-12,   3.34219821e-13],\n",
       "        [ -1.70027511e-06,   1.63333027e-06],\n",
       "        [ -3.11530209e+00,  -1.83846664e+00],\n",
       "        [ -8.57260078e-03,  -1.13442587e-03],\n",
       "        [ -1.90609193e+00,   6.04007244e-01],\n",
       "        [  7.96509348e-03,  -8.61149374e-03],\n",
       "        [  1.25467977e-06,  -2.35853167e-06],\n",
       "        [ -3.08377171e+00,   1.49740696e-01],\n",
       "        [  7.30684519e-01,   2.12994289e+00],\n",
       "        [ -4.19157396e-25,   4.14728435e-25],\n",
       "        [ -5.71925938e-03,   3.44994757e-03],\n",
       "        [  6.57924730e-03,   8.89963412e-04],\n",
       "        [ -5.80350957e-07,  -1.37076768e-08],\n",
       "        [ -9.07159250e-17,   1.76644933e-17],\n",
       "        [ -6.20644132e-05,   3.39413527e-05],\n",
       "        [ -1.07408422e-11,   9.25460750e-12],\n",
       "        [  3.00449017e-07,   3.24913373e-07],\n",
       "        [ -2.72263223e-13,   1.14225632e-13],\n",
       "        [ -2.61617794e-09,   9.03122022e-11],\n",
       "        [ -6.87170599e-04,   2.16637956e-04],\n",
       "        [ -7.24377145e-08,   2.79433987e-08],\n",
       "        [ -2.55055241e-02,   6.91651925e-03],\n",
       "        [ -1.33574512e-02,  -9.44868568e-03],\n",
       "        [ -1.56285218e-09,   1.16605747e-09],\n",
       "        [ -2.48483177e-02,   4.70869802e-03],\n",
       "        [ -2.55928421e+00,   2.86472082e-01],\n",
       "        [  4.31790113e+00,   1.97720575e+00],\n",
       "        [ -1.21522141e+00,   6.10770583e-01],\n",
       "        [ -1.65335392e-03,  -2.32022372e-04],\n",
       "        [ -9.53912171e-10,   6.45117071e-10],\n",
       "        [ -1.53132285e-09,   1.08910103e-09],\n",
       "        [ -2.88466072e-06,   3.56345527e-06],\n",
       "        [  1.38664484e+00,  -1.30815136e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
